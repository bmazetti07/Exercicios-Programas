\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\begin{document}
\begin{center}
	Lista 3 - MAC 0460
	
	Bruno Mazetti Saito - 11221838
\end{center}

\textbf{3 - } Um ponto interessante a destacar sobre as redes neurais, é a sua capacidade de representar qualquer função contínua utilizando apenas uma camada oculta, mas também, uma característica a ser destacada também é a utilização de várias camadas como perceptrons para poder fazer diferentes separações dos dados diferente da linear mais comum. Uma qualidade interessante do SVM é a flexibilidade em relação aos possíveis dados ruidosos presentes no conjunto de treinamento, além disso, também podemos considerar a utilização dos \textit{kernel tricks} para poder fazer um ajuste de dados não linearmente separáveis utilizando uma transformação neles para torna-los linearmente separáveis. \\ \\

\textbf{4 - } A validação serve basicamente como uma ajuda para o conjunto de treinamento, já que por meio dela podemos escolher os melhores hiperparâmetros para o modelo em questão afim de obter um bom resultado. O teste, diferente da validação, não interfere no processo de treinamento, já que serve para se poder ter uma estimativa de como o modelo ajustado irá perfomar em um outro conjunto de dados. \\ \\

\textbf{5 - } Ao meu entendimento, \textit{overfitting} se trata de um problema em que o algoritmo "aprende de mais", ou seja, se um conjunto de treinamento possuir muitos dados ruidosos, o processo de aprendizagem pde ser comprometido ao tentar ajustar o modelo de forma que estes ruídos sejam ajustados corretamente, resultando em um ajuste não muito bom para outros conjuntos de dados não usados no treinamento. Desse modo, podemos detecta-lo por meio do conjunto de teste, já que se o modelo apresentar uma precisão muito alta para o conjunto de treinamento mas, em compensação, uma não tão alta para o conjunto de teste, isso nos dá uma clara evidência de \textit{overfitting}. Para combate-lo podemos utilizar a técnica de validação, utilizando, por exemplo, diversos subconjuntos do conjunto de treinamento para que possamos ter um controle maior sobre os possíveis sobreajustes. \\ \\

\textbf{6 - }
• Acredito que dos tópicos destacados consegui ter um entendimento razoável em cerca de 75\%;

• Um assunto que tive um entendimento conseidrável foi o de overfitting. O processo de overfitting é, basicamente, um problema encontrado nos algoritmos de treinamento que acabam minimizando o erro dentro da amostra mais do que deveriam, o que acaba resultando em um ajuste não muito bom para os dados fora do conjunto de treinamento;

• Sobre os assuntos de \textit{clustering} e redes neurais convolucionadas não tive um avanço no conhecimento sobre eles principalmente pelo acúmulo de atividades do final do semestre, então acabei não vendo muito sobre estes assuntos;

• Na minha opinião, considero que tive um aproveitamento da disciplina de 7.5, apesar de não ter acompanhado alguns assuntos com a intenção que pretendia, aumentei o interesse pela área e gostei de implementar os algoritmos nos EP's. \\ \\

\textbf{7 - } • Acabei estudando e procurando a respeito cerca de 80\% dos conteúdos cobertos na disciplina;

• Realizei todas as atividades propostas;

• Assisti à grande maioria das aulas ao vivo, e quando não pude, procurei assitir às gravações depois. Consideraria que tive uma presença de 85\%. \\ \\

\textbf{8 - } Como dito no itens anteriores, tive um entendimento da maior parte dos conteúdos cobertos e assisti à grande parte das aulas também, embora não acabe participando muito com perguntas por preferência, além disso, acho que tive um bom desempenho nas tarefas propostas. No início do semestre esta era a disciplina que estava mais empolgado em cursar, e a implementação dos EP's aumentou mais o meu interesse pela área, e inclusive, me fez considerar a realização do TCC na área.
\end{document}